version: "3.8"

services:
  dttp-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dttp-ai-server-prod
    restart: unless-stopped
    ports:
      - "8000:5000"
    env_file:
      - .env.prod
    volumes:
      # Persist model and embeddings cache
      - model_cache:/app/model_cache
      - embeddings_cache:/app/embeddings_cache
      - logs:/app/logs
    networks:
      - dttp-network
    # Memory limits for large ML models
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  model_cache:
    driver: local
  embeddings_cache:
    driver: local
  logs:
    driver: local

networks:
  dttp-network:
    driver: bridge
